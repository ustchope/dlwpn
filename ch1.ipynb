{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "silver-hobby",
   "metadata": {},
   "source": [
    "> 初版，没有修正。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sized-dance",
   "metadata": {},
   "source": [
    "# 什么是人工智能？"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "inside-blade",
   "metadata": {},
   "source": [
    "> 本章涵盖\n",
    "> * 基本概念的高级定义\n",
    "> * 机器学习发展时间表\n",
    "> * 深度学习日益普及和未来潜力背后的关键因素"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "according-photography",
   "metadata": {},
   "source": [
    "在过去几年中，人工智能 (AI) 一直是媒体激烈炒作的主题。机器学习、深度学习和人工智能出现在无数文章中，通常在\n",
    "具有技术意识的出版物。我们承诺智能聊天机器人、自动驾驶的未来汽车和虚拟助手——未来有时会笼罩在阴暗的光线中，有时则像乌托邦，人类的工作将稀缺，大多数经济活动将由机器人处理或人工智能代理。对于机器学习的未来或当前从业者来说，重要的是能够识别噪音中的信号，以便您可以从过度炒作的新闻稿。我们的未来岌岌可危，这是一个你可以积极参与的未来玩：阅读本书后，您将成为开发这些人工智能系统的人之一。那么让我们解决这些问题：到目前为止，深度学习取得了什么成就？它有多重要？在哪我们接下来去吗？你应该相信炒作吗？\n",
    "\n",
    "本章提供了有关人工智能、机器学习和深度学习的基本背景。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prospective-experience",
   "metadata": {},
   "source": [
    "## 人工智能、机器学习和深度学习"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "domestic-bleeding",
   "metadata": {},
   "source": [
    "首先，当我们提到人工智能时，我们需要清楚地定义我们在谈论什么。 什么是人工智能、机器学习和深度学习？ 它们之间的关系如何？"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "compatible-allergy",
   "metadata": {},
   "source": [
    "![](https://tva1.sinaimg.cn/large/008i3skNly1gsbuaf2bd5j61380pwafi02.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "satisfied-gardening",
   "metadata": {},
   "source": [
    "### 人工智能"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "controlled-infrared",
   "metadata": {},
   "source": [
    "人工智能诞生于 1950 年代，当时来自新兴计算机科学领域的少数先驱开始询问是否可以让计算机“思考”——这个问题的影响我们今天仍在探索。\n",
    "\n",
    "虽然许多潜在的想法已经在几年甚至几十年前酝酿，但“人工智能”终于在 1956 年成为一个研究领域，当时达特茅斯学院年轻的数学助理教授约翰麦卡锡组织了一个夏季研讨会，根据以下提议："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "israeli-friendly",
   "metadata": {},
   "source": [
    "> *这项研究是基于这样一个猜想进行的，即学习的每个方面或智能的任何其他特征原则上都可以精确地描述，以至于可以用机器来模拟它。 将尝试寻找如何让机器使用语言，形成抽象和概念，解决现在留给人类的各种问题，并改进自己。 我们认为，如果精心挑选的一组科学家共同研究一个夏天，就可以在这些问题中的一个或多个方面取得重大进展。*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "collective-auditor",
   "metadata": {},
   "source": [
    "夏末，研讨会在没有完全解开它开始调查的谜题的情况下结束。 尽管如此，许多后来成为该领域先驱的人参加了会议，并引发了一场至今仍在进行的知识革命。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "laden-thriller",
   "metadata": {},
   "source": [
    "简而言之，人工智能可以被描述为将通常由人类执行的智能任务自动化的努力。 因此，人工智能是一个包含机器学习和深度学习的通用领域，但也包括更多可能不涉及任何学习的方法。 想想直到 80 年代，大多数 AI 教科书根本没有提到“学习”！ 例如，早期的国际象棋程序只涉及程序员编写的硬编码规则，不符合机器学习的要求。 事实上，在相当长的一段时间里，大多数专家认为，通过让程序员手工编写足够大的显式规则集来操纵存储在显式数据库中的知识，可以实现人类级别的人工智能。 这种方法被称为符号人工智能。 从 1950 年代到 1980 年代后期，它是 AI 的主要范式，并在 1980 年代专家系统热潮期间达到了顶峰。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "studied-abuse",
   "metadata": {},
   "source": [
    "尽管符号 AI 被证明适合解决定义明确的逻辑问题，例如下棋，但结果证明很难找出解决更复杂的模糊问题的明确规则，例如图像分类、语音识别或自然语言翻译 . 出现了一种取代符号 AI 的新方法：机器学习。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "convertible-planet",
   "metadata": {},
   "source": [
    "### 机器学习"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "invisible-equipment",
   "metadata": {},
   "source": [
    "在维多利亚时代的英格兰，艾达·洛夫莱斯夫人是查尔斯·巴贝奇（Charles Babbage）的朋友和合作者，后者是分析引擎的发明者：第一台已知的通用机械计算机。 尽管具有远见卓识且遥遥领先于那个时代，但分析引擎在 1830 年代和 1840 年代设计时并不意味着它是通用计算机，因为通用计算的概念尚未发明。 它只是作为一种使用机械操作来自动化数学分析领域的某些计算的方式——因此，名称为分析引擎。 因此，它是早期尝试以齿轮形式编码数学运算的智力后裔，例如 Pascaline，或 Leibniz 的步数计算器，Pascaline 的改进版本。 由 Blaise Pascal 于 1642 年（19 岁！）设计，Pascaline 是世界上第一台机械计算器——它可以加、减、乘、甚至除数字。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "crucial-virus",
   "metadata": {},
   "source": [
    "1843 年，Ada Lovelace 评论分析机的发明："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ethical-maine",
   "metadata": {},
   "source": [
    "> *分析引擎没有任何自命不凡的目的。 它可以做任何我们知道如何命令它执行的事情。......它的职责是帮助我们提供我们已经熟悉的东西。*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "outstanding-register",
   "metadata": {},
   "source": [
    "即使有 177 年的历史视角，洛夫莱斯夫人的观察仍然引人注目。 通用计算机是否可以“创造”任何东西，还是只能执行我们人类完全理解的乏味过程？ 它可能有任何原创思想吗？ 它可以借鉴经验吗？ 它可以展示创造力吗？"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "understood-requirement",
   "metadata": {},
   "source": [
    "她的言论后来被人工智能先驱艾伦·图灵引用为“洛夫莱斯夫人的反对意见”，在他 1950 年具有里程碑意义的论文“计算机与智能”中，介绍了图灵测试以及塑造人工智能的关键概念。 图灵认为——在当时非常具有挑衅性——计算机原则上可以模拟人类智能的所有方面。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "direct-holmes",
   "metadata": {},
   "source": [
    "![](https://tva1.sinaimg.cn/large/008i3skNly1gsbumwxs8mj310q0jgwhr.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "curious-newsletter",
   "metadata": {},
   "source": [
    "机器学习系统不是明确编程的。 它提供了许多与任务相关的经过训练的示例，并在这些示例中找到统计结构，最终允许系统提出自动执行任务的规则。 例如，如果您希望自动执行标记假期图片的任务，您可以向机器学习系统展示许多已被人类标记的图片示例，系统将学习将特定图片与特定标签相关联的统计规则。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "executed-minutes",
   "metadata": {},
   "source": [
    "尽管机器学习在 1990 年代才开始蓬勃发展，但它已迅速成为人工智能最流行和最成功的子领域，这是由更快的硬件和更大数据集的可用性驱动的趋势。机器学习与数理统计相关，但它在几个重要方面与统计学不同——就像医学与化学相关，但不能归结为化学，因为医学处理的是具有自己独特属性的独特系统。与统计学不同，机器学习倾向于处理大型、复杂的数据集（例如包含数百万张图像的数据集，每个图像由数万个像素组成），而贝叶斯分析等经典统计分析对于这些数据集是不切实际的。因此，机器学习，尤其是深度学习，展示的数学理论相对较少——可能太少了——而且从根本上说是一门工程学科。与理论物理或数学不同，机器学习是一个由经验发现驱动的非常实用的领域，并且深深依赖于软件和硬件的进步。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "invisible-frederick",
   "metadata": {},
   "source": [
    "### 从数据中学习规则和表示"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "approximate-movement",
   "metadata": {},
   "source": [
    "要定义深度学习并理解深度学习与其他机器学习方法之间的区别，首先我们需要了解机器学习算法的作用。 我们刚刚说过，机器学习会发现执行数据处理任务的规则，给出预期的例子。 因此，要进行机器学习，我们需要三件事：\n",
    "* 输入数据点——例如，如果任务是语音识别，这些数据点可能是人们说话的声音文件。 如果任务是图像标记，则它们可能是图片。\n",
    "* 预期输出示例——在语音识别任务中，这些可能是人工生成的声音文件转录本。 在图像任务中，预期输出可能是诸如“狗”、“猫”等标签。\n",
    "* 一种衡量算法是否做得好的方法——这是确定算法当前输出与其预期输出之间的距离所必需的。 测量作为反馈信号来调整算法的工作方式。这个调整步骤就是我们所说的学习。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "documentary-sister",
   "metadata": {},
   "source": [
    "机器学习模型将其输入数据转换为有意义的输出，这是一个通过接触已知输入和输出示例“学习”的过程。 因此，机器学习和深度学习的核心问题是有意义地转换数据：换句话说，学习手头输入数据的有用表示——让我们更接近预期输出的表示。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "popular-inflation",
   "metadata": {},
   "source": [
    "在我们进一步讨论之前：什么是表征？ 从本质上讲，它是一种看待数据的不同方式——表示或编码数据。 例如，彩色图像可以以 RGB 格式（红-绿-蓝）或 HSV 格式（色调-饱和度-值）进行编码：这是同一数据的两种不同表示。 一些用一种表示可能很困难的任务用另一种表示可能变得容易。 例如，任务“选择图像中的所有红色像素”在 RGB 格式中更简单，而“使图像不那么饱和”在 HSV 格式中更简单。 机器学习模型都是关于为输入数据找到合适的表示——数据的转换，使其更适合手头的任务。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "billion-rouge",
   "metadata": {},
   "source": [
    "让我们把它具体化。 考虑一个 x 轴、一个 y 轴和一些由它们在 (x, y) 系统中的坐标表示的点，如图 1.3 所示。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "middle-charleston",
   "metadata": {},
   "source": [
    "![](https://tva1.sinaimg.cn/large/008i3skNly1gsc0gd7xpvj30o00qagnu.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deluxe-sacrifice",
   "metadata": {},
   "source": [
    "如您所见，我们有一些白点和一些黑点。 假设我们想要开发一种算法，该算法可以获取一个点的坐标 (x, y) 并输出该点可能是黑色还是白色。 在这种情况下，\n",
    "* 输入是我们点的坐标。\n",
    "* 预期输出是我们点的颜色。\n",
    "* 例如，衡量我们的算法是否做得好的一种方法可以是正确分类的点的百分比。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dietary-bangkok",
   "metadata": {},
   "source": [
    "我们在这里需要的是我们数据的新表示，它可以将白点与黑点清晰地分开。 在许多其他可能性中，我们可以使用的一种转换是坐标变化，如图 1.4 所示。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lyric-dietary",
   "metadata": {},
   "source": [
    "![](https://tva1.sinaimg.cn/large/008i3skNly1gsc0jbrgarj31fs0k4dkh.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reflected-spending",
   "metadata": {},
   "source": [
    "在这个新的坐标系中，我们点的坐标可以说是我们数据的新表示。 这是一个很好的！ 通过这种表示，黑/白分类问题可以表示为一个简单的规则：黑点使得 x 0，或“白点使得 x < 0”。 这种新的表示，结合这个简单的规则，巧妙地解决了分类问题。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adaptive-label",
   "metadata": {},
   "source": [
    "在这种情况下，我们手动定义了坐标变化：我们使用我们的人类智慧来提出我们自己适当的数据表示。 这对于这样一个极其简单的\n",
    "问题，但如果任务是对手写数字的图像进行分类，你能做同样的事情吗？ 你能写下明确的、计算机可执行的图像转换，以阐明 6 和 8 之间、1 和 7 之间的差异，以及各种不同的笔迹吗？"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "utility-trustee",
   "metadata": {},
   "source": [
    "这在一定程度上是可能的。 基于数字表示的规则，例如“闭环数”或垂直和水平像素直方图（另一种表示）可以很好地区分手写数字。 但是手工找到这样有用的表示是一项艰巨的工作，并且您可以想象由此产生的基于规则的系统将是脆弱的——维护起来是一场噩梦。 每次遇到会打破您仔细考虑的规则的新手写示例时，您都必须添加新的数据转换和新规则，同时考虑它们与之前每个规则的交互。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "explicit-confusion",
   "metadata": {},
   "source": [
    "你可能在想，如果这个过程如此痛苦，我们可以自动化吗？ 如果我们尝试系统地搜索不同的数据和基于它们的规则的自动生成的表示集，通过使用某些开发数据集中正确分类的数字百分比作为反馈来识别好的表示怎么办？ 然后我们将进行机器学习。 在机器学习的上下文中，描述了学习数据转换的自动搜索过程，该过程产生一些数据的有用表示，由一些反馈信号引导 - 表示适合解决手头任务的更简单的规则。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "decent-rolling",
   "metadata": {},
   "source": [
    "例如），但它们也可以是线性投影、平移、非线性操作（例如选择所有点使得 x 0），等等。 机器学习算法在寻找这些转换方面通常没有创造性； 他们只是在搜索一组预定义的操作，称为假设空间。 例如，所有可能坐标变化的空间将是我们在二维坐标分类示例中的假设空间。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efficient-maldives",
   "metadata": {},
   "source": [
    "这些变换可以是坐标变化（如在我们的 2D 坐标分类示例中），但它们也可以是线性投影、平移、非线性操作（例如选择所有点使 x 0）等。 机器学习算法在寻找这些转换方面通常没有创造性； 他们只是在搜索一组预定义的操作，称为假设空间。 例如，所有可能坐标变化的空间将是我们在二维坐标分类示例中的假设空间。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "opponent-petite",
   "metadata": {},
   "source": [
    "简而言之，这就是机器学习的含义：使用来自反馈信号的指导，在预定义的可能性空间内，在某些输入数据上搜索有用的表示和规则。 这个简单的想法可以解决非常广泛的智力任务，从语音识别到自动驾驶。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cutting-renewal",
   "metadata": {},
   "source": [
    "现在您已经理解了我们的意思，让我们来看看是什么让学习深度学习变得特别。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "detailed-biodiversity",
   "metadata": {},
   "source": [
    "### “深度学习”中的“深度”"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "juvenile-wealth",
   "metadata": {},
   "source": [
    "深度学习是机器学习的一个特定子领域：一种从数据中学习表征的新方法，它强调学习越来越有意义的表征的连续层。 “深度学习”中的“深度”并不是指通过该方法实现的任何更深入的理解；相反，它代表了连续表示层的想法。有多少层对数据模型有贡献称为深度模型。该领域的其他合适名称可能是分层表示学习或分层表示学习。现代深度学习通常涉及数十甚至数百个连续的表示层——它们都是通过接触训练数据自动学习的。同时，其他机器学习方法往往只专注于学习数据的一层或两层表示（例如，获取像素直方图，然后应用分类规则）；因此，它们有时被称为浅层学习。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "resistant-morocco",
   "metadata": {},
   "source": [
    "在深度学习中，这些分层表示（几乎总是）通过称为神经网络的模型来学习，这些模型由堆叠在彼此之上的文字层构成。术语神经网络是对神经生物学的引用，但尽管深度学习中的一些核心概念部分是从我们对大脑（尤其是视觉皮层）的理解中汲取灵感而发展起来的，但深度学习模型并不是大脑模型.没有证据表明大脑实现了现代深度学习模型中使用的学习机制。您可能会看到一些流行科学文章，声称深度学习的工作原理类似于大脑或模仿大脑，但事实并非如此。会很混乱\n",
    "并且对于该领域的新手来说，将深度学习视为与神经生物学有任何关系会适得其反；你不需要“就像我们的思想一样”的神秘感和神秘感，你也可以忘记任何你可能读过的关于深度学习和生物学之间假设联系的东西。就我们的目的而言，深度学习是一种从数据中学习表征的数学框架。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "settled-round",
   "metadata": {},
   "source": [
    "深度学习算法学习到的表征是什么样的？ 让我们来看看多层深度的网络（见图 1.5）如何转换数字图像以识别它是什么数字。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "loose-magnet",
   "metadata": {},
   "source": [
    "![](https://tva1.sinaimg.cn/large/008i3skNly1gsd5kpige5j31fi0mogp4.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "floating-measurement",
   "metadata": {},
   "source": [
    "正如您在图 1.6 中看到的那样，网络将数字图像转换为与原始图像越来越不同的表示，并且对最终结果的信息越来越多。 您可以将深度网络视为一个多阶段的信息蒸馏过程，其中信息通过连续的过滤器并越来越多地出现（即，对某些任务有用的纯化）。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "recent-mathematics",
   "metadata": {},
   "source": [
    "![](https://tva1.sinaimg.cn/large/008i3skNly1gsd5lruulmj613y0oe44502.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "manual-fabric",
   "metadata": {},
   "source": [
    "从技术上讲，这就是深度学习：一种学习数据表示的多阶段方法。 这是一个简单的想法——但事实证明，非常简单的机制，充分扩展，最终可能看起来像魔法。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "asian-guide",
   "metadata": {},
   "source": [
    "### 用三幅图了解深度学习的工作原理"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ruled-conducting",
   "metadata": {},
   "source": [
    "此时，您知道机器学习是将输入（例如图像）映射到目标（例如标签“猫”），这是通过观察输入和目标的许多示例来完成的。 您还知道，深度神经网络通过一系列简单数据转换（层）的深层序列进行输入到目标的映射，并且这些数据转换是通过接触示例来学习的。 现在让我们具体看看这种学习是如何发生的。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "plastic-representation",
   "metadata": {},
   "source": [
    "层对其输入数据执行的操作的规范存储在层的 中，其权重本质上是一堆数字。 用技术术语来说，我们会说一个层实现的转换是由它的权重参数化的（见图 1.7）。 （权重有时也称为层的参数。）在这种情况下，意味着为网络中所有层的权重找到一组学习值，以便网络将示例输入正确映射到其相关目标。 但问题是：一个深度神经网络可以包含数千万个参数。 为所有参数找到正确的值似乎是一项艰巨的任务，尤其是考虑到修改一个参数的值会影响所有其他参数的行为！"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "complimentary-franklin",
   "metadata": {},
   "source": [
    "![](https://tva1.sinaimg.cn/large/008i3skNly1gsd5oxl5tnj315y0nojvx.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dense-scroll",
   "metadata": {},
   "source": [
    "要控制某事，首先您需要能够观察它。 要控制神经网络的输出，您需要能够测量此输出与您的预期相差多远。 这是网络损失函数的工作，有时也称为目标函数成本或函数。 损失函数采用网络的预测和真实目标（您希望网络输出的内容）并计算距离分数，捕捉网络在此特定示例上的表现（见图 1.8）。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "certified-accused",
   "metadata": {},
   "source": [
    "![](https://tva1.sinaimg.cn/large/008i3skNly1gsd5q124crj30t20oyadh.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fossil-valley",
   "metadata": {},
   "source": [
    "深度学习的基本技巧是使用这个分数作为反馈信号来稍微调整权重的值，以降低当前示例的损失分数（见图 1.9）。 这种调整是 的工作，它实现了所谓的优化器反向传播算法：深度学习中的中心算法。 下一章更详细地解释了反向传播的工作原理。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "closed-accent",
   "metadata": {},
   "source": [
    "![](https://tva1.sinaimg.cn/large/008i3skNly1gsd5r8opa7j30yo0t4te6.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "robust-glucose",
   "metadata": {},
   "source": [
    "最初，网络的权重被分配随机值，因此网络只是实现了一系列随机变换。 自然，它的输出与理想情况相差甚远，因此损失分数非常高。 但是对于网络处理的每个示例，权重都会在正确的方向上进行一些调整，并且损失分数会降低。 这是训练循环，它重复足够多的次数（通常是对数千个示例进行数十次迭代），产生最小化损失函数的权重值。 具有最小损失的网络是输出尽可能接近目标的网络：经过训练的网络。 再一次，这是一个简单的机制，一旦扩展，最终看起来就像魔法一样。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "statutory-praise",
   "metadata": {},
   "source": [
    "### 到目前为止，深度学习取得了什么成就"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "social-recommendation",
   "metadata": {},
   "source": [
    "尽管深度学习是机器学习的一个相当古老的子领域，但它直到 2010 年代初才崭露头角。 在此后的几年里，它在该领域取得了巨大的进步，在感知任务甚至自然语言处理任务上取得了显著成果——这些问题涉及人类看起来很自然和直觉但长期以来机器难以捉摸的技能。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "collaborative-orlando",
   "metadata": {},
   "source": [
    "尤其是，深度学习在机器学习历史上困难的领域实现了以下突破：\n",
    "\n",
    "* 接近人类水平的图像分类\n",
    "* 接近人类水平的语音转录\n",
    "* 接近人类水平的手写转录\n",
    "* 显着改进的机器翻译\n",
    "* 显着改进的文本到语音转换\n",
    "* 数字助理，例如 Google Assistant 和 Amazon Alexa\n",
    "* 接近人类水平的自动驾驶\n",
    "* 改进了 Google、百度或 Bing 使用的广告定位\n",
    "* 改进了网络上的搜索结果\n",
    "* 能够回答自然语言问题\n",
    "* 超人围棋"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "above-youth",
   "metadata": {},
   "source": [
    "我们仍在探索深度学习的全部功能。 我们已经开始将它成功地应用于各种各样的问题，这些问题被认为是不可能解决的\n",
    "多年前——自动转录梵蒂冈秘密档案馆中的数万份古代手稿，使用简单的智能手机检测和分类田间植物病害，协助肿瘤学家或放射科医生解释医学影像数据，预测洪水、飓风或 甚至地震......随着每一个里程碑，我们越来越接近一个深度学习帮助我们从事每一项活动和人类努力的每一个领域的时代——科学、医学、制造、能源、交通、软件开发、农业，甚至艺术创作 ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "radio-residence",
   "metadata": {},
   "source": [
    "### 不要相信短期炒作"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "retired-vertical",
   "metadata": {},
   "source": [
    "尽管近年来深度学习取得了非凡的成就，但对该领域在未来十年能够实现的目标的期望往往远高于可能实现的目标。 尽管自动驾驶汽车等一些改变世界的应用已经触手可及，但在很长一段时间内，还有更多应用可能难以捉摸，例如可信的对话系统、跨任意语言的人类级别的机器翻译以及人类级别的自然语言理解。 特别是，不应太认真地谈论人类水平的通用智能。 短期内被寄予厚望的风险在于，随着技术无法交付，研究投资将枯竭，长期放缓进度。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "killing-cartoon",
   "metadata": {},
   "source": [
    "这已经发生过。过去，人工智能经历了两次强烈的乐观，然后是失望和怀疑，最终导致资金短缺。它始于 1960 年代的符号 AI。在那些早期，关于人工智能的预测很高。符号 AI 方法最著名的先驱和支持者之一是 Marvin Minsky，他在 1967 年声称，“在一代人之内……创造‘人工智能’的问题将得到实质性解决。”三年后的 1970 年，他做出了更精确的量化预测：“在三到八年内，我们将拥有一台具有普通人一般智能的机器。”到 2020 年，这样的成就似乎还遥遥无期——到目前为止，我们无法预测需要多长时间——但在 1960 年代和 1970 年代初，几位专家认为它指日可待（如今天做很多人）。几年后，由于这些高期望未能实现，研究人员和政府资金离开了该领域，标志着第一个开始（指核冬天，人工智能冬天，因为这是冷战高峰期之后不久）。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "addressed-sunglasses",
   "metadata": {},
   "source": [
    "这不会是最后一个。 在 1980 年代，符号 AI 专家系统的新尝试开始在大公司中聚集。 一些最初的成功故事引发了一波投资浪潮，世界各地的公司都成立了自己的内部 AI 部门来开发专家系统。 1985 年左右，公司每年在这项技术上的支出超过 10 亿美元； 但到 1990 年代初，事实证明，这些系统维护成本高、难以扩展且范围有限，因此兴趣逐渐消退。 就这样开始了第二个人工智能冬天。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "assigned-murray",
   "metadata": {},
   "source": [
    "我们目前可能正在目睹人工智能炒作和失望的第三轮周期——我们仍处于极度乐观的阶段。 最好缓和我们对短期的期望，并确保不太熟悉该领域技术方面的人清楚地了解深度学习可以和不能提供什么。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "artificial-persian",
   "metadata": {},
   "source": [
    "### 人工智能的承诺"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interpreted-stereo",
   "metadata": {},
   "source": [
    "尽管我们对人工智能的短期期望可能不切实际，但长期前景看起来是光明的。我们才刚刚开始将深度学习应用于许多可以证明具有变革性的重要问题，从医疗诊断到数字助理。人工智能研究在过去十年中以惊人的速度向前推进，这在很大程度上是由于人工智能的短暂历史中从未有过的资​​金水平，但到目前为止，这种进展相对较少进入产品和流程形成我们的世界。深度学习的大部分研究成果尚未应用，或者至少没有应用于它们可以解决的所有行业的所有问题。你的医生还没有使用人工智能，你的会计师也没有。您在日常生活中可能不会经常使用 AI 技术。当然，你可以问你的智能手机简单的问题并得到合理的答案，你可以得到相当有用的Amazon.com 上的产品推荐，您可以在 Google 相册上搜索“生日”，并立即找到您女儿上个月生日聚会的照片。这与此类技术过去的地位相去甚远。但这样的工具仍然只是我们日常生活的配件。人工智能尚未转变为我们工作、思考和生活方式的核心。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rapid-recovery",
   "metadata": {},
   "source": [
    "现在，似乎很难相信人工智能会对我们的世界产生巨大影响，因为它还没有广泛部署——就像在 1995 年一样，很难相信互联网对未来的影响 . 那时，大多数人没有看到互联网与他们的关系以及它将如何改变他们的生活。 今天的深度学习和人工智能也是如此。 但请不要误会：人工智能即将到来。 在不远的将来，人工智能将是你的助手，甚至是你的朋友； 它将回答您的问题，帮助教育您的孩子，并关注您的健康。 它将把您的杂货送到您家门口，并将您从 A 点带到 B 点。它将成为您与日益复杂和信息密集型世界的接口。 而且，更重要的是，人工智能将帮助人类科学家在从基因组学到数学的所有科学领域取得新的突破性发现，从而帮助整个人类向前发展。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "trying-retro",
   "metadata": {},
   "source": [
    "在此过程中，我们可能会遇到一些挫折，甚至可能会迎来一个新的人工智能冬天——就像互联网行业在 1998 年至 1999 年被过度炒作，并在整个 2000 年代初期遭受投资枯竭的崩溃一样。 但我们最终会到达那里。 人工智能最终将应用于构成我们社会和日常生活的几乎所有过程，就像今天的互联网一样。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "seasonal-leather",
   "metadata": {},
   "source": [
    "不要相信短期炒作，但要相信长期愿景。 人工智能可能需要一段时间才能发挥其真正的潜力——这种潜力是任何人都不敢想象的全部潜力——但人工智能即将到来，它将以一种奇妙的方式改变我们的世界。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "laden-custody",
   "metadata": {},
   "source": [
    "## 深度学习之前：机器学习简史"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "british-brown",
   "metadata": {},
   "source": [
    "深度学习已经达到了人工智能历史上前所未有的公众关注和行业投资水平，但它并不是机器学习的第一种成功形式。 可以肯定地说，当今行业中使用的大多数机器学习算法都不是深度学习算法。 深度学习并不总是适合这项工作的工具——有时没有足够的数据可供深度学习应用，有时问题可以通过不同的方法更好地解决\n",
    "算法。 如果深度学习是您第一次接触机器学习，那么您可能会发现自己处于这样的境地：您所拥有的只是深度学习的锤子，而每个机器学习问题都开始看起来像钉子。 不落入这个陷阱的唯一方法是熟悉其他方法并在适当的时候练习它们。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "short-sustainability",
   "metadata": {},
   "source": [
    "对经典机器学习方法的详细讨论超出了本书的范围，但我们将简要介绍它们并描述它们开发的历史背景。 这将使我们能够将深度学习置于更广泛的机器学习背景中，并更好地了解深度学习的来源及其重要性。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "japanese-memorial",
   "metadata": {},
   "source": [
    "### 概率建模"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "public-artist",
   "metadata": {},
   "source": [
    "概率建模是将统计学原理应用于数据分析。 它是最早的机器学习形式之一，至今仍在广泛使用。 该类别中最著名的算法之一是朴素贝叶斯算法。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "elder-speaking",
   "metadata": {},
   "source": [
    "朴素贝叶斯是一种基于应用贝叶斯定理的机器学习分类器，同时假设输入数据中的特征都是独立的（一个强大的或“朴素”的假设，这就是名称的来源）。 这种形式的数据分析早于计算机，并且在其第一次计算机实现之前的几十年（很可能可以追溯到 1950 年代）被手工应用。 贝叶斯定理和统计学的基础可以追溯到 18 世纪，这些是开始使用朴素贝叶斯分类器所需的全部内容。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "expressed-failure",
   "metadata": {},
   "source": [
    "一个密切相关的模型是逻辑回归（简称 logreg），它有时被认为是现代机器学习的“Hello World”。 不要被它的名字误导——logreg 是一种分类算法而不是回归算法。 很像朴素贝叶斯，logreg 早于计算，但由于其简单和通用的性质，它直到今天仍然有用。 通常，数据科学家首先会尝试使用数据集来了解手头的分类任务。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stuck-interference",
   "metadata": {},
   "source": [
    "### 早期的神经网络"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sustained-adoption",
   "metadata": {},
   "source": [
    "神经网络的早期迭代已被这些页面中涵盖的现代变体完全取代，但了解深度学习的起源是有帮助的。 尽管神经网络的核心思想早在 1950 年代就以玩具的形式进行了研究，但这种方法花了几十年才开始。 很长一段时间，缺失的部分是训练大型神经网络的有效方法。 这种情况在 1980 年代中期发生了变化，当时多人独立重新发现了反向传播算法——一种使用梯度下降优化训练参数运算链的方法（本书稍后将精确定义这些概念）——并开始将其应用于神经网络网络。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "roman-payroll",
   "metadata": {},
   "source": [
    "神经网络的第一个成功实际应用是在 1989 年来自贝尔实验室，当时 Yann LeCun 结合了卷积神经网络和反向传播的早期思想，并将它们应用于手写数字分类问题。 由此产生的名为 LeNet 的网络在 1990 年代被美国邮政服务用于自动读取邮件信封上的邮政编码。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hollow-performance",
   "metadata": {},
   "source": [
    "### 核方法"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "willing-reservoir",
   "metadata": {},
   "source": [
    "随着神经网络在 1990 年代开始在研究人员中获得一些尊重，由于首次成功，一种新的机器学习方法声名鹊起并迅速将神经网络送回遗忘：内核方法。 核方法是一组分类算法，其中最著名的是支持向量机 (SVM)。 SVM 的现代公式由 Vladimir Vapnik 和 Corinna Cortes 于 1990 年代初在贝尔实验室开发并于 1995 年发表，尽管 Vapnik 和 Alexey 3 Chervonenkis 早在 1963 年就发表了较旧的线性公式。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "english-utility",
   "metadata": {},
   "source": [
    "SVM 是一种分类算法，它通过查找分隔两个类的“决策边界”来工作，如下所示："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "associate-prospect",
   "metadata": {},
   "source": [
    "![](https://tva1.sinaimg.cn/large/008i3skNly1gsdgksc8joj30iw0qwju2.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "manual-chassis",
   "metadata": {},
   "source": [
    "SVM 分两步寻找这些边界：\n",
    "\n",
    "* 数据被映射到一个新的高维表示，其中决策边界可以表示为一个超平面（如果数据是二维的，如图 1.10 所示，超平面将是一条直线。 \n",
    "* 一个好的决策边界（分离超平面）是通过尝试最大化超平面和来自每个类的最近数据点之间的距离来计算的，这一步骤称为最大化边距。 这允许边界很好地泛化到训练数据集之外的新样本。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "empty-access",
   "metadata": {},
   "source": [
    "在分类问题变得更简单的情况下，将数据映射到高维表示的技术在纸面上可能看起来不错，但实际上它通常在计算上难以处理。 这就是进来的地方（内核方法被命名为内核技巧的关键思想）。 这是它的要点：要在新的表示空间中找到好的决策超平面，您不必明确计算新空间中点的坐标； 您只需要计算该空间中点对之间的距离，这可以使用核函数有效地完成。 核函数是一种计算上易于处理的操作，它将初始空间中的任意两点映射到目标表示空间中这些点之间的距离，完全绕过了新表示的显式计算。 核函数通常是手工制作的，而不是从数据中学习的——在 SVM 的情况下，只学习分离超平面。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "amateur-newfoundland",
   "metadata": {},
   "source": [
    "在开发它们时，SVM 在简单的分类问题上表现出最先进的性能，并且是为数不多的由广泛理论支持并适合认真数学分析的机器学习方法之一，使它们易于理解和易于解释。 由于这些有用的特性，SVM 长期以来在该领域非常流行。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "discrete-economy",
   "metadata": {},
   "source": [
    "但事实证明，SVM 难以扩展到大型数据集，并且无法为图像分类等感知问题提供良好的结果。 由于 SVM 是一种浅层方法，将 SVM 应用于感知问题需要首先手动提取有用的表示（称为特征工程的步骤），这既困难又脆弱。 例如，如果你想使用 SVM 对手写数字进行分类，你不能从原始像素开始，你应该首先手动找到使问题更易于处理的有用表示——就像我们之前提到的像素直方图。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "productive-criticism",
   "metadata": {},
   "source": [
    "### 决策树、随机森林和梯度提升机"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "higher-anthony",
   "metadata": {},
   "source": [
    "决策树是类似于流程图的结构，可让您对输入数据点进行分类或在给定输入的情况下预测输出值（见图 1.11）。 它们很容易可视化和解释。 从数据中学习的决策树在 2000 年代开始受到重大研究兴趣，到 2010 年，它们通常比核方法更受欢迎。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "noble-neighbor",
   "metadata": {},
   "source": [
    "![](https://tva1.sinaimg.cn/large/008i3skNly1gsdgrjgb6sj30v20ju0w8.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "suspended-helen",
   "metadata": {},
   "source": [
    "特别是，随机森林算法引入了一种稳健、实用的决策树学习方法，涉及构建大量专门的决策树，然后集成它们的输出。随机森林适用于范围广泛的问题，您可以说它们几乎总是任何浅层机器学习任务的次佳算法。当流行的机器学习竞赛网站 Kaggle ( kaggle.com) 于 2010 年启动时，kaggle.com 随机森林迅速成为平台上的宠儿——直到 2014 年梯度提升机器接管。梯度提升机，很像随机森林，是一种基于集成弱预测模型（通常是决策树）的机器学习技术。它使用梯度提升，这是一种通过迭代训练专门解决先前模型弱点的新模型来改进任何机器学习模型的方法。应用于决策树，梯度提升技术的使用导致模型在大多数情况下严格优于随机森林，同时具有相似的属性。它可能是当今处理非感知数据的最佳算法之一。除了深度学习，它也是 Kaggle 比赛中最常用的技术之一。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "missing-hungarian",
   "metadata": {},
   "source": [
    "### 回到神经网络"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "liked-state",
   "metadata": {},
   "source": [
    "2010 年左右，虽然神经网络几乎完全被科学界完全回避，但仍有一些人在神经网络方面的工作开始取得重要突破：多伦多大学的 Geoffrey Hinton、蒙特利尔大学的 Yoshua Bengio 小组 、纽约大学的 Yann LeCun 和瑞士的 IDSIA。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rough-charter",
   "metadata": {},
   "source": [
    "2011 年，来自 IDSIA 的 Dan Ciresan 开始使用 GPU 训练的深度神经网络赢得学术图像分类竞赛——这是现代深度学习的第一个实际成功。但分水岭在 2012 年出现，Hinton 的团队参加了一年一度的大规模图像分类挑战 ImageNet（ImageNet 大规模视觉识别挑战赛，简称 ILSVRC）。 ImageNet 挑战在当时是出了名的困难，包括在对 140 万张图像进行训练后将高分辨率彩色图像分类为 1000 个不同的类别。 2011 年，基于经典计算机视觉方法的获胜模型的前五名准确率仅为 74.3%。然后，在 2012 年，由 Alex Krizhevsky 领导并由 Geoffrey Hinton 担任顾问的团队能够实现 83.6% 的前五名准确率——这是一项重大突破。从那以后，每年的比赛都由深度卷积神经网络主导。到 2015 年，获胜者达到了 96.4% 的准确率，ImageNet 上的分类任务被认为是一个完全解决的问题。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "formed-emission",
   "metadata": {},
   "source": [
    "自 2012 年以来，深度卷积神经网络 (convnets) 已成为 convnets 所有计算机视觉任务的首选算法； 更一般地说，它们适用于所有感知任务。 在 2015 年之后的任何主要计算机视觉会议上，几乎不可能找到不涉及某种形式的卷积神经网络的演讲。 同时，深度学习也在许多其他类型的问题中找到了应用，例如自然语言处理。 它已经在广泛的应用中完全取代了 SVM 和决策树。 例如，几年来，欧洲核子研究组织 (CERN) 使用基于决策树的方法来分析来自大型强子对撞机 (LHC) 的 ATLAS 探测器的粒子数据； 但是 CERN 最终转向了基于 Keras 的深度神经网络，因为它们具有更高的性能并且易于在大型数据集上进行训练。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "loaded-spain",
   "metadata": {},
   "source": [
    "### 是什么让深度学习与众不同"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "functional-worker",
   "metadata": {},
   "source": [
    "深度学习发展如此迅速的主要原因是它在许多问题上提供了更好的性能。 但这不是唯一的原因。 深度学习还使问题解决变得更加容易，因为它完全自动化了曾经是机器学习工作流程中最关键的步骤：特征工程。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tropical-living",
   "metadata": {},
   "source": [
    "以前的机器学习技术——浅层学习——只涉及将输入数据转换成一个或两个连续的表示空间，通常通过简单的转换，例如\n",
    "高维非线性投影 (SVM) 或决策树。 但复杂问题所需的精细表示通常无法通过此类技术获得。 因此，人类必须竭尽全力使初始输入数据更易于通过这些方法进行处理：他们必须为他们的数据手动设计良好的表示层。 这称为特征工程。 另一方面，深度学习完全自动化了这一步：通过深度学习，您可以一次性学习所有特征，而不必自己设计它们。 这大大简化了机器学习工作流程，通常用单一、简单、端到端的深度学习模型取代复杂的多级管道。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "advanced-swedish",
   "metadata": {},
   "source": [
    "你可能会问，如果问题的关键是有多个连续的表示层，那么浅层方法是否可以重复应用来模拟深度学习的效果？在实践中，\n",
    "浅层学习方法的连续应用会带来快速递减的回报，因为三层模型中最优的第一层表示层并不是一层或两层模型中最优的第一层。深度学习的变革之处在于它允许模型同时学习所有表示层，而不是连续学习（所谓的共同贪婪）。通过联合特征学习，每当模型调整其内部特征之一时，依赖它的所有其他特征都会自动适应变化，而无需人工干预。一切都由一个单一的反馈信号监督：模型中的每一个变化都为最终目标服务。这比贪婪地堆叠浅层模型要强大得多，因为它允许通过将复杂的抽象表示分解成长系列的中间空间（层）来学习；每个空间都只是一个简单的\n",
    "与之前的转变不同。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hungarian-inspector",
   "metadata": {},
   "source": [
    "这是深度学习如何从数据中学习的两个基本特征：开发越来越复杂的表示的增量、逐层方式，以及这些中间增量表示是联合学习的事实，每一层都更新以遵循两者 上层的代表性需求和下层的需求。 总之，这两个特性使深度学习比以前的机器学习方法更加成功。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "breathing-houston",
   "metadata": {},
   "source": [
    "### 现代机器学习领域"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "southern-logistics",
   "metadata": {},
   "source": [
    "了解机器学习算法和工具的当前格局的一个好方法是查看 Kaggle 上的机器学习竞赛。 由于其竞争激烈的环境\n",
    "（有些比赛有数千名参赛者和数百万美元的奖金）并且针对涵盖的各种机器学习问题，Kaggle 提供了一种现实的方法来评估哪些有效，哪些无效。 那么，什么样的算法才能可靠地赢得比赛呢？ 顶尖进入者使用哪些工具？"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mounted-legislation",
   "metadata": {},
   "source": [
    "2019 年初，Kaggle 进行了一项调查，询问自 2017 年以来在任何比赛中排名前五的团队在比赛中使用的主要软件工具（见图 1.12）。 事实证明，顶级团队倾向于使用深度学习方法（最常通过 Keras 库）或梯度提升树（最常通过 LightGBM 或 XGBoost 库）。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "controlled-pleasure",
   "metadata": {},
   "source": [
    "![](https://tva1.sinaimg.cn/large/008i3skNly1gsdh2fj9nyj310k0u0n5q.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "burning-chapel",
   "metadata": {},
   "source": [
    "这也不仅仅是比赛冠军。 Kaggle 还在全球范围内对机器学习和数据科学专业人士进行年度调查。 有成千上万的受访者，这项调查是我们关于行业状况的最可靠来源之一。 图 1.13 显示了不同机器学习软件框架的使用百分比。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "legal-rolling",
   "metadata": {},
   "source": [
    "![](https://tva1.sinaimg.cn/large/008i3skNly1gsdh4io6dnj30sq0pwdic.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "quick-vegetarian",
   "metadata": {},
   "source": [
    "从 2016 年到 2020 年，整个机器学习和数据科学行业一直被这两种方法主导：深度学习和梯度提升树。 具体来说，梯度提升树用于处理结构化数据可用的问题，而深度学习用于图像分类等感知问题。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dirty-penny",
   "metadata": {},
   "source": [
    "梯度提升树的用户倾向于使用 Scikit-Learn、XGBoost 或 LightGBM。 同时，大多数深度学习从业者使用 Keras，通常与其父框架 TensorFlow 结合使用。 这些工具的共同点是它们都是 Python 库：Python 是迄今为止机器学习和数据科学使用最广泛的语言。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mounted-disco",
   "metadata": {},
   "source": [
    "为了在当今的应用机器学习中取得成功，您应该最熟悉以下两种技术：梯度提升树，用于浅层学习问题； 和深度学习，用于感知问题。 从技术角度来说，这意味着你需要熟悉 Scikit-Learn、XGBoost 和 Keras——目前主导 Kaggle 比赛的三个库。 有了这本书，你已经又近了一大步。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "humanitarian-circumstances",
   "metadata": {},
   "source": [
    "## 为什么是深度学习？ 为什么现在？"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "little-japan",
   "metadata": {},
   "source": [
    "计算机视觉卷积神经网络深度学习和反向传播的两个关键思想——在 1990 年已经得到很好的理解。长短期记忆 (LSTM) 算法是时间序列深度学习的基础，于 1997 年开发，几乎没有 从此改变。 那么为什么深度学习在 2012 年之后才开始兴起呢？ 这两个十年发生了什么变化？"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dimensional-workstation",
   "metadata": {},
   "source": [
    "总的来说，三种技术力量正在推动机器学习的进步：\n",
    "* 硬件\n",
    "* 数据集和基准\n",
    "* 算法进步"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "private-genome",
   "metadata": {},
   "source": [
    "因为该领域是由实验结果而不是理论指导的，所以只有当有合适的数据和硬件来尝试新想法（或扩大旧想法，通常情况下）时，算法进步才有可能。 机器学习不是数学或物理学，主要的进步可以用一支笔和一张纸来完成。 这是一门工程科学。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "legal-withdrawal",
   "metadata": {},
   "source": [
    "整个 1990 年代和 2000 年代的真正瓶颈是数据和硬件。 但那段时间发生的事情是这样的：互联网开始腾飞，高性能图形芯片应运而生，以满足游戏市场的需求。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "industrial-stress",
   "metadata": {},
   "source": [
    "### 硬件"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "russian-karma",
   "metadata": {},
   "source": [
    "从 1990 年到 2010 年，现成的 CPU 的速度提高了大约 5,000 倍。 因此，现在可以在您的笔记本电脑上运行小型深度学习模型，而这在 25 年前是难以处理的。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "choice-award",
   "metadata": {},
   "source": [
    "但是，计算机视觉或语音识别中使用的典型深度学习模型需要的计算能力比笔记本电脑所能提供的计算能力高出几个数量级。整个 2000 年代，NVIDIA 和 AMD 等公司投资数十亿美元开发快速、大规模并行芯片（图形处理单元，或 GPU），以支持越来越逼真的视频游戏的图形——旨在渲染复杂 3D 场景的廉价、单一用途的超级计算机实时显示在您的屏幕上。 2007 年，NVIDIA 推出了 CUDA (developer.nvidia.com/about-cuda)，这是其 GPU 系列的编程接口，这项投资使科学界受益。从物理建模开始，少数 GPU 开始取代各种高度并行化应用程序中的大量 CPU 集群。深度神经网络，主要由许多小的矩​​阵乘法组成，也是高度可并行化的； 2011 年左右，一些研究人员开始编写神经网络的 CUDA 实现——Dan Ciresan 和 Alex Krizhevsky 是第一批。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "french-palestine",
   "metadata": {},
   "source": [
    "发生的事情是游戏市场补贴了下一代人工智能应用的超级计算。 有时，大事始于游戏。 今天，NVIDIA Titan RTX，一款在 2019 年底售价 2500 美元的 GPU，可以在单精度（每秒 16 万亿次操作）下提供 16 TeraFLOPs 的峰值。 这大约是 float32 的 500 倍\n",
    "计算能力超过 1990 年世界上最快的超级计算机 Intel Touchstone Delta。 在 Titan RTX 上，只需几个小时就可以训练出在 2012 年或 2013 年左右赢得 ILSVRC 竞赛的那种 ImageNet 模型。与此同时，大公司在数百个 GPU 的集群上训练深度学习模型。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "running-rainbow",
   "metadata": {},
   "source": [
    "更重要的是，深度学习行业已经超越了 GPU，并且正在投资于越来越专业、高效的深度学习芯片。 2016 年，在其年度 I/O 大会上，谷歌公布了其张量处理单元 (TPU) 项目：一种从头开始开发的新芯片设计，用于运行深度神经网络，与顶级芯片相比，速度明显更快，能源效率更高。 线 GPU。 今天，2020年，TPU卡的第三次代表420\n",
    "TeraFLOPs 的计算能力。 这是 1990 年英特尔 Touchstone Delta 的 10,000 倍。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dated-integration",
   "metadata": {},
   "source": [
    "这些 TPU 卡旨在组装成大规模配置，称为“吊舱”。 一个 pod（1024 个 TPU 卡）的峰值为 100 PetaFLOP。 就规模而言，这大约是目前最大的超级计算机（橡树岭国家实验室的 IBM 峰会）峰值计算能力的 10%，其中包含 27,000 个 NVIDIA GPU，峰值约为 1.1 ExaFLOP。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "competent-species",
   "metadata": {},
   "source": [
    "### 数据"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unavailable-intention",
   "metadata": {},
   "source": [
    "人工智能有时被誉为新的工业革命。 如果深度学习是这场革命的蒸汽机，那么数据就是它的煤炭：为我们的智能机器提供动力的原材料，没有煤炭，一切皆不可能。 在数据方面，除了过去 20 年存储硬件的指数级进步（遵循摩尔定律）之外，改变游戏规则的是互联网的兴起，这使得收集和分发用于机器学习的超大数据集成为可能 . 今天，大公司处理没有互联网就无法收集的图像数据集、视频数据集和自然语言数据集。 例如，Flickr 上用户生成的图像标签一直是计算机视觉数据的宝库。 YouTube 视频也是如此。 维基百科是自然语言处理的关键数据集。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "overall-cambodia",
   "metadata": {},
   "source": [
    "如果有一个数据集成为深度学习兴起的催化剂，那就是 ImageNet 数据集，它由 140 万张图像组成，这些图像已经用 1,000 个图像类别（每张图像一个类别）进行了人工标注。 但让 ImageNet 与众不同的不仅仅是它的大尺寸，还有与之相关的年度竞争。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alternate-realtor",
   "metadata": {},
   "source": [
    "正如 Kaggle 自 2010 年以来一直在证明的那样，公开比赛是激励研究人员和工程师挑战极限的绝佳方式。 拥有研究人员竞相击败的共同基准极大地帮助了深度学习的兴起，突出了深度学习相对于经典机器学习方法的成功。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pregnant-headline",
   "metadata": {},
   "source": [
    "### 算法"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "directed-services",
   "metadata": {},
   "source": [
    "除了硬件和数据，直到 2000 年代后期，我们还缺少一种可靠的方法来训练非常深的神经网络。 因此，神经网络仍然相当浅，仅使用一两层表示； 因此，他们无法与更精细的浅层方法（如 SVM 和随机森林）相比。 关键问题是梯度传播通过深层堆叠的问题。 随着层数的增加，用于训练神经网络的反馈信号会逐渐消失。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "asian-authorization",
   "metadata": {},
   "source": [
    "随着几个简单但重要的算法改进的出现，这种情况在 2009-2010 年左右发生了变化，这些改进允许更好的梯度传播：\n",
    "\n",
    "* 更好的神经层激活函数 \n",
    "* 更好的权重初始化方案，从逐层预训练开始，然后很快被放弃\n",
    "* 更好的优化方案，例如 RMSProp 和 Adam。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eastern-shanghai",
   "metadata": {},
   "source": [
    "只有当这些改进开始允许训练具有 10 层或更多层的模型时，深度学习才开始大放异彩。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hybrid-cathedral",
   "metadata": {},
   "source": [
    "最后，在 2014、2015 和 2016 年，发现了更高级的帮助梯度传播的方法，例如批量归一化、残差连接和深度可分离卷积。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "trained-victoria",
   "metadata": {},
   "source": [
    "今天，我们可以从头开始训练任意深度的模型。 这开启了超大型模型的使用，这些模型具有相当大的表示能力——也就是说，它们编码了非常丰富的假设空间。 这种极端的可扩展性是现代深度学习的定义特征之一。 具有数千万层和数千万参数的大规模模型架构在计算机视觉（例如 ResNet、Inception 或 Xception 等架构）和自然语言处理（例如大型 基于 Transformer 的架构，例如 BERT、GPT-2 或 XLNet）。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "raising-hypothetical",
   "metadata": {},
   "source": [
    "### 新一轮投资"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "defined-murder",
   "metadata": {},
   "source": [
    "随着深度学习在 2012 年至 2013 年成为计算机视觉的最新技术，并最终用于所有感知任务，行业领导者注意到了这一点。 随之而来的是一波渐进的行业投资浪潮，远远超出了人工智能历史上前所未有的规模。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "instant-discipline",
   "metadata": {},
   "source": [
    "![](https://tva1.sinaimg.cn/large/008i3skNgy1gsgwqc6uosj30xk0py421.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "operational-brown",
   "metadata": {},
   "source": [
    "2011 年，就在深度学习成为焦点之前，全球人工智能风险投资总额不到 10 亿美元，几乎全部用于浅层机器学习方法的实际应用。 2015 年，它已升至超过 50 亿美元，2017 年达到惊人的 160 亿美元。 数以百计的初创公司在这几年推出，试图利用深度学习的炒作。 与此同时，谷歌、亚马逊和微软等大型科技公司对内部研究部门的投资很可能使风险投资资金的流动相形见绌。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "statewide-fundamentals",
   "metadata": {},
   "source": [
    "机器学习——尤其是深度学习——已经成为这些科技巨头产品战略的核心。 2015 年底，Google 首席执行官 Sundar Pichai 表示：*“机器学习是一种核心的变革性方式，我们正在通过它重新思考我们如何做所有事情。我们正在深思熟虑地将其应用于我们的所有产品，无论是搜索、广告还是 YouTube 或 Play。我们还处于早期阶段，但您会看到我们以系统的方式将机器学习应用于所有这些领域。”*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adult-finish",
   "metadata": {},
   "source": [
    "在这一波投资浪潮下，从事深度学习的人数在不到十年的时间里从几百人变成了几万人，研究进展也达到了疯狂的速度。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "satisfactory-journey",
   "metadata": {},
   "source": [
    "### 深度学习的民主化"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "coastal-indiana",
   "metadata": {},
   "source": [
    "推动深度学习新面孔流入的关键因素之一是该领域使用的工具集的民主化。 在早期，进行深度学习需要大量的 C++ 和 CUDA 专业知识，而很少有人拥有这些专业知识。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "developing-crest",
   "metadata": {},
   "source": [
    "如今，基本的 Python 脚本技能足以进行高级深度学习研究。 这主要是由现已解散的 Theano 库和 TensorFlow 库的开发驱动的——这两个符号张量操作框架支持自动微分，大大简化了新模型的实现——以及用户- 友好的库，例如 Keras，它使深度学习像操作乐高积木一样简单。\n",
    "\n",
    "在 2015 年初发布后，Keras 迅速成为大量新创业公司、研究生和研究人员进入该领域的首选深度学习解决方案。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "forced-musical",
   "metadata": {},
   "source": [
    "### 能否持续？"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "classical-hopkins",
   "metadata": {},
   "source": [
    "深度神经网络有什么特别之处，使它们成为公司投资和研究人员蜂拥而至的“正确”方法？ 或者深度学习只是一种可能不会持久的时尚？ 20 年后我们还会使用深度神经网络吗？"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "starting-melbourne",
   "metadata": {},
   "source": [
    "深度学习有几个特性证明其作为人工智能革命的地位是合理的，而且它会继续存在。 二十年后我们可能不会使用神经网络，但无论我们使用什么，都将直接继承现代深度学习及其核心概念。 这些重要的属性可以大致分为三类：\n",
    "* 简单性——深度学习消除了对特征工程的需求，用简单的、端到端的可训练模型取代了复杂、脆弱、工程繁重的管道，这些模型通常只使用五六个不同的张量运算构建。\n",
    "\n",
    "* 可扩展性——深度学习非常适合在 GPU 或 TPU 上并行化，因此它可以充分利用摩尔定律。此外，深度学习模型是通过迭代小批量数据来训练的，允许它们在任意大小的数据集上进行训练。 （唯一的瓶颈是可用的并行计算能力，由于摩尔定律，这是一个快速移动的障碍。）\n",
    "\n",
    "* 多功能性和可重用性——与许多先前的机器学习方法不同，深度学习模型可以在额外的数据上进行训练，而无需从头开始，使其适用于持续在线学习——这是非常大的生产模型的重要属性。此外，经过训练的深度学习模型是可重复使用的，因此可以重复使用：例如，可以将经过训练用于图像分类的深度学习模型放入视频处理管道中。这使我们能够将以前的工作重新投入到日益复杂和强大的模型中。这也使得深度学习适用于相当小的数据集。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nearby-firewall",
   "metadata": {},
   "source": [
    "深度学习只出现在聚光灯下几年，我们可能还没有确定它可以做什么的全部范围。每一年，我们都会了解新的用例和工程改进，以消除以前的限制。在科学革命之后，进步通常遵循一条 sigmoid 曲线：它从一个快速进步的时期开始，随着研究人员遇到困难的限制而逐渐稳定下来，然后进一步的改进成为渐进式的。\n",
    "\n",
    "当我在 2016 年写这本书的第一版时，我预测深度学习仍处于 sigmoid 的前半部分，在接下来的几年里会有更多的变革性进展。这在实践中得到了证明，因为 2017 年和 2018 年见证了基于 Transformer 的自然语言处理深度学习模型的兴起，这是该领域的一场革命，而深度学习也在计算机视觉和语音识别方面不断取得稳步进展.今天，在 2021 年，深度学习似乎已经进入了那个 sigmoid 的后半部分。我们仍然应该期待未来几年的重大进展，但我们可能已经走出了爆炸性进展的初始阶段。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "brave-commission",
   "metadata": {},
   "source": [
    "今天让我非常兴奋的一个领域是将深度学习技术部署到它可以解决的每个问题上——这个列表是无止境的。 深度学习仍然是一场正在酝酿中的革命，需要很多年才能充分发挥其潜力。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
